<!DOCTYPE html>
<html>

<head>
    <meta charset="UTF-8" />
    <link href="https://fonts.googleapis.com/css2?family=Lato:wght@200;300;400;600;700;900&display=swap"
        rel="stylesheet">
    <link rel="stylesheet" type="text/css" href="assets/css/style.css" />
    <title> Fu-Yun Wang </title>
</head>

<body>
    <div style="width:1000px;margin: 0px auto;">
        <header id="header" width="400px" style="display:flex;justify-content: space-around;">
            <a href="#profile-intro">Home</a>
            <a href="#news">News</a>
            <a href="#preprint">Preprint</a>
            <a href="#research">Research</a>
            <!-- <a href="#projects">Projects</a> -->
        </header>
        <div id="profile">
            <div id="profile-pic">
                <img src="assets/images/profile.jpg" />
            </div>
            <div id="profile-intro">
                <div id="profile-name">Fu-Yun Wang</div>
                <div id="profile-email">fywang@link.cuhk.edu.hk</div>
                <p>
                    Fu-Yun Wang is a first-year Ph.D. student at MMLab@CUHK, supervised by Professor Xiaogang Wang and Professor Hongsheng Li. 
                </p>
                <p>
                    Prior to this, he obtained his B.Eng. from Nanjing University in 2023 with first honor, supervised by Professor Han-Jia Ye and Dr. Da-Wei Zhou.
                </p>
                <p>
                    Currently, he works on diffusion acceleration with  Dr. <a href="https://drinkingcoder.github.io/">Zhaoyang Huang</a>. 
                </p>
                
                <div>
                    <a href="https://github.com/g-u-n">
                        Github
                    </a>
                    /
                    <a href="https://scholar.google.com/citations?user=R15m3J4AAAAJ">
                        Google Scholar
                    </a>
                    </a>
                </div>
            </div>
            <div style="clear: both;"></div>
        </div>

        <div class="section" id="news">
            <h1>News</h1>
            <ul>
                <li> <b>APR 2024</b> Motion-I2V is accepted by SIGGRAPH 2024.
                <li> <b>JAN 2024</b> A co-author paper is accepted by CVPR 2024.
                <li> <b>JAN 2024</b> Release AnimateLCM, a pioneer work for fast video generation.
                <li> <b>Aug 2023</b> Beginning of Ph.D. study at Multimedia Laboratory.
            </ul>
            <p></p>
            <div style="clear: both;"></div>
        </div>
        <div class="divider"></div>
        <div style="display:flex;flex-direction: column;" id="preprint">
            <h1>Preprint</h1>
            <div>
                <a href="https://be-your-outpainter.github.io/" style="height: 14em;" class="research-thumb">
                    <video width="320" height="auto" autoplay loop muted>
                        <source src="assets/vids/outpaint.mp4" type="video/mp4">
                    </video>
                </a>
                <a href="https://be-your-outpainter.github.io/" class="research-proj-title">
                   Be-Your-Outpainter: Mastering Video Outpainting through Input-Specific Adaptation
                </a>
                <p>
                    <a style="color:#000;" href="https://g-u-n.github.io/"><b>Fu-Yun Wang*</b></a>,
                    <a style="color:#000;">Xiaoshi Wu*</a>,
                    <a style="color:#000;">Zhaoyang Huang</a>,
                    <a style="color:#000;">Xiaoyu Shi</a>,
                    <a style="color:#000;">Dazhong Shen</a>,
                    <a style="color:#000;">Guanglu Song</a>,
                    <a style="color:#000;">Yu Liu</a>,
                    <a style="color:#000;">Hongsheng Li</a>,

                    <br><em>arXiv. 2024</em><br>
                    <a href="https://be-your-outpainter.github.io/">Project Page</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                    <a href="https://arxiv.org/abs/2403.13745">ArXiv</a>
                </p>
            </div>
            <div>
                <a href="https://animatelcm.github.io" style="height: 14em;" class="research-thumb">
                    <video width="320" height="auto" autoplay loop muted>
                        <source src="assets/vids/animatelcm.mp4" type="video/mp4">
                    </video>

                </a>
                <a href="https://animatelcm.github.io" class="research-proj-title">
                   AnimateLCM: Accelerating the Animation of Personalized Diffusion Models and Adapters with Decoupled Consistency Learning
                </a>
                <p>
                    <a style="color:#000;" href="https://g-u-n.github.io/"><b>Fu-Yun Wang</b></a>,
                    <a style="color:#000;" >Zhaoyang Huang</a>,
                    <a style="color:#000;" >Xiaoyu Shi</a>,
                    <a style="color:#000;" >Weikang Bian</a>,
                    <a style="color:#000;" >Guanglu Song</a>,
                    <a style="color:#000;" >Yu Liu</a>,
                    <a style="color:#000;" >Hongsheng Li</a>

                    <br><em>arXiv. 2024</em><br>
                    <a href="https://github.com/G-U-N/AnimateLCM">Github</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                    <a href="https://arxiv.org/abs/2402.00769">ArXiv</a>
                </p>
            </div>

            <div>
                <a href="https://g-u-n.github.io/" style="height: 14em;" class="research-thumb">
                    <img src="assets/images/lvdm.png"
                        style=" margin-bottom:0px;"
                        alt="">
                </a>
                <a href="https://g-u-n.github.io/" class="research-proj-title">
                    Gen-L-Video: Multi-Text to Long Video Generation via Temporal Co-Denoising
                </a>
                <p>
                    <a style="color:#000;" href="https://g-u-n.github.io/"><b>Fu-Yun Wang</b></a>,
                    <a style="color:#000;" >Wenshuo Chen</a>,
                    <a style="color:#000;" >Guanglu Song</a>,
                    <a style="color:#000;" >Han-Jia Ye</a>,
                    <a style="color:#000;" >Yu Liu</a>,
                    <a style="color:#000;" >Hongsheng Li</a>
                    <br><em>arXiv:2305.18264 </em><br>
                    <a href="https://github.com/G-U-N/Gen-L-Video">Github</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                    <a href="https://arxiv.org/abs/2305.18264">ArXiv</a>
                </p>
            </div>
            <div>
        <div style="display:flex;flex-direction: column;" id="research">
            <h1>Research</h1>
        <div>
            <a href="https://xiaoyushi97.github.io/Motion-I2V/" style="height: 14em;" class="research-thumb">
                <video width="320" height="auto" autoplay loop muted>
                    <source src="assets/vids/motioni2v.mp4" type="video/mp4">
                </video>
            </a>
            <a href="https://xiaoyushi97.github.io/Motion-I2V/" class="research-proj-title">
                Motion-I2V: Consistent and Controllable Image-to-Video Generation with Explicit Motion Modeling
            </a>
            <p>
                <a style="color:#000;">Xiaoyu Shi*</a>,
                <a style="color:#000;">Zhaoyang Huang*</a>,
                <a style="color:#000;" href="https://g-u-n.github.io/"><b>Fu-Yun Wang*</b></a>,
                <a style="color:#000;">Weikang Bian*</a>,
                <a style="color:#000;">Dasong Li</a>,
                <a style="color:#000;">Yi Zhang</a>,
                <a style="color:#000;">Manyuan Zhang</a>,
                <a style="color:#000;">Kachun Cheung</a>,
                <a style="color:#000;">Simon See</a>,
                <a style="color:#000;">Hongwei Qin</a>,
                <a style="color:#000;">Jifeng Dai</a>,
                <a style="color:#000;">Hongsheng Li</a>
                <br>
                <em>Special Interest Group on GRAPHics and Interactive Techniques.<strong><i style="color:#1e90ff">SIGGRAPH 2024</i></strong>.</em><br>
                <a href="https://xiaoyushi97.github.io/Motion-I2V/">Project Page</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                <a href="https://arxiv.org/abs/2401.15977">ArXiv</a><br>
                <strong><i style="color:red;">SIGGRAPH 2024 Technical Papers Trailer</i></strong>
            </p>
        </div>

            <div>
                <a href="https://g-u-n.github.io/" style="height: 14em;" class="research-thumb">
                    <img src="assets/images/s-cfg.png"
                        style=" margin-bottom:0px;"
                        alt="">
                </a>
                <a href="https://g-u-n.github.io/" class="research-proj-title">
                    Rethinking the Spatial Inconsistency in Classifier-Free Diffusion Guidance
                </a>
                <p>
                    
                    <a style="color:#000;" >Dazhong Shen</a>,
                    <a style="color:#000;">Guanglu Song</a>,
                    <a style="color:#000;">Zeyue Xue</a>,
                    <a style="color:#000;" href="https://g-u-n.github.io/"><b>Fu-Yun Wang</b></a>,
                    <a style="color:#000;" > Yu Liu</a>,
                    <br><em>IEEE Conference on Computer Vision and Pattern Recognition.<strong><i style="color:#1e90ff">CVPR 2024</i></strong>.</em><br>
                </p>
            </div>
            <div>
                <a href="https://g-u-n.github.io/" style="height: 14em;" class="research-thumb">
                    <img src="assets/images/foster.jpg"
                        style=" margin-bottom:0px;"
                        alt="">
                </a>
                <a href="https://g-u-n.github.io/" class="research-proj-title">
                    FOSTER: Feature Boosting and Compression for Class-Incremental Learning
                </a>
                <p>
                    <a style="color:#000;" href="https://g-u-n.github.io/"><b>Fu-Yun Wang</b></a>,
                    <a style="color:#000;" href="http://www.lamda.nju.edu.cn/zhoudw/">Da-Wei Zhou</a>,
                    <a style="color:#000;" href="http://www.lamda.nju.edu.cn/yehj/">Han-Jia Ye</a>,
                    <a style="color:#000;" href="http://www.lamda.nju.edu.cn/yehj/">De-Chuan Zhan</a>
                    <br><em>European Conference on Computer Vision. <strong><i style="color:#1e90ff">ECCV 2022</i></strong>.</em><br>
                    <a href="https://github.com/G-U-N/ECCV22-FOSTER">Github</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                    <a href="https://arxiv.org/abs/2204.04662">ArXiv</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                    <img src="https://img.shields.io/badge/dynamic/json?style=plastic&amp;labelColor=f6f6f6&amp;color=9cf&amp;style=flat&amp;label=Citations&amp;logo=Google%20Scholar&amp;query=publications%5B2%5D.citations&amp;url=https%3A%2F%2Fcse.bth.se%2F~fer%2Fgooglescholar-api%2Fgooglescholar.php%3Fuser%3DkMNaR-YAAAAJ" />
                </p>
            </div>
            <div>
                <a href="https://g-u-n.github.io/" style="height: 14em;" class="research-thumb">
                    <img src="assets/images/3ef.png"
                        style=" margin-bottom:0px;"
                        alt="">
                </a>
                <a href="https://g-u-n.github.io/" class="research-proj-title">
                    BEEF: Bi-Compatible Class-Incremental via Energy-Based Expansion and Fusion
                </a>
                <p>
                    <a style="color:#000;" href="https://g-u-n.github.io/"><b>Fu-Yun Wang</b></a>,
                    <a style="color:#000;" href="http://www.lamda.nju.edu.cn/zhoudw/">Da-Wei Zhou</a>,
                    <a style="color:#000;" href="http://www.lamda.nju.edu.cn/yehj/">Han-Jia Ye</a>,
                    <a style="color:#000;" href="http://www.lamda.nju.edu.cn/yehj/">De-Chuan Zhan</a>
                    <br><em>Eleventh International Conference on Learning Representations. <strong><i style="color:#1e90ff">ICLR 2023</i></strong>.</em><br>
                    <a href="https://github.com/G-U-N/ICLR23-BEEF">Github</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                    <a href="https://openreview.net/forum?id=iP77_axu0h3">Paper</a>
                </p>
            </div>
            <div>
                <a href="https://g-u-n.github.io/" style="height: 14em;" class="research-thumb">
                    <img src="assets/images/fact.jpg"
                        style=" margin-bottom:0px;"
                        alt="">
                </a>
                <a href="https://g-u-n.github.io/" class="research-proj-title">
                    FACT: Forward Compatible Few-Shot Class-Incremental Learning
                </a>
                <p>
                    <a style="color:#000;" href="http://www.lamda.nju.edu.cn/zhoudw/">Da-Wei Zhou</a>,
                    <a style="color:#000;" href="https://g-u-n.github.io/"><b>Fu-Yun Wang</b></a>,
                    <a style="color:#000;" href="http://www.lamda.nju.edu.cn/yehj/">Han-Jia Ye</a>,
                    <a style="color: #000;">Liang Ma</a>,
                    <a style="color: #000;">Shiliang Pu</a>,
                    <a style="color:#000;" href="http://www.lamda.nju.edu.cn/yehj/">De-Chuan Zhan</a>
                    <br><em>IEEE Conference on Computer Vision and Pattern Recognition.<strong><i style="color:#1e90ff">CVPR 2022</i></strong>.</em><br>
                    <a href="https://github.com/zhoudw-zdw/CVPR22-Fact">Github</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                    <a href="https://arxiv.org/abs/2203.06953">ArXiv</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                    <img src="https://img.shields.io/badge/dynamic/json?style=plastic&amp;labelColor=f6f6f6&amp;color=9cf&amp;style=flat&amp;label=Citations&amp;logo=Google%20Scholar&amp;query=publications%5B1%5D.citations&amp;url=https%3A%2F%2Fcse.bth.se%2F~fer%2Fgooglescholar-api%2Fgooglescholar.php%3Fuser%3DkMNaR-YAAAAJ" />                </p>
            </div>
            <div>
                <a href="https://g-u-n.github.io/" style="height: 14em;" class="research-thumb">
                    <img src="assets/images/pycil.png"
                        style=" margin-bottom:0px;"
                        alt="">
                </a>
                <a href="https://g-u-n.github.io/" class="research-proj-title">
                    PyCIL: A Python Toolbox for Class-Incremental Learning
                </a>
                <p>
                    <a style="color:#000;" href="http://www.lamda.nju.edu.cn/zhoudw/">Da-Wei Zhou*</a>,
                    <a style="color:#000;" href="https://g-u-n.github.io/"><b>Fu-Yun Wang*</b></a>,
                    <a style="color:#000;" href="http://www.lamda.nju.edu.cn/yehj/">Han-Jia Ye</a>,
                    <a style="color:#000;" href="http://www.lamda.nju.edu.cn/yehj/">De-Chuan Zhan</a>
                    <br><em>SCIENCE CHINA Information Sciences. <strong><i style="color:#1e90ff">SCIS</i></strong>.</em><br>
                    <a href="https://github.com/G-U-N/PyCIL">Github</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                    <a href="https://arxiv.org/abs/2112.12533">ArXiv</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                    <a href="https://mp.weixin.qq.com/s/A472p7XGZMhAMAR2wyHZJw">Media</a> &nbsp;&nbsp;&bull;&nbsp;&nbsp;<img src="https://img.shields.io/github/stars/G-U-N/PyCIL?style=flat&amp;label=Stars&amp;logo=github&amp;labelColor=f6f6f6&amp;color=9cf&amp;logoColor=020d12" />
                    <img src="https://img.shields.io/github/forks/G-U-N/PyCIL?style=flat&amp;label=Forks&amp;logo=github&amp;labelColor=f6f6f6&amp;color=9cf&amp;logoColor=020d12" />

                </p>
            </div>
            <div>
            <div class="divider"></div>
            <div class="section" id="awards">
                <h1>Awards & Honor</h1>
                <ul>
                    <li> <b>2023</b> HKPFS (Hong Kong PhD Fellowship Scheme)
                    <li> <b>2023</b> Outstanding Graduate of Nanjing University
                    <li> <b>2023</b> Outstanding Undergraduate Thesis of Nanjing University
                    <li> <b>2022</b> Sensetime Scholarship
                    <li> <b>2022</b> Huawei Scholarship
                    <li> <b>2021</b> National Scholarship 
                </ul>
                <p></p>
                <div style="clear: both;"></div>
            </div>
            <div class="section" id="services">
                <h1>Sevices</h1>
                <ul>
                    Reviewer of TPAMI, TCSVT, PRL, CVPR2023, NeurIPS2023, ICLR2024, CVPR2024, ICML2024, ECCV 2024, BMVC 2024
                </ul>
                <p></p>
                <div style="clear: both;"></div>
            </div>
            <div style="clear: both;"></div>
        </div>
    </div>
    <script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=CDfFGbXsSkbODpLYvxuFm3Ivejv6Ju6FkxS1dau4g-8&cl=ffffff&w=a"></script> 

</body>

</html>
